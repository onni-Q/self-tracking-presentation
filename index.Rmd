---
title: "'Strongly Recommended' Revisiting Decisional Privacy to Judge Hypernudging in Self-Tracking Technologies"
output: html_document
---
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Roboto', sans-serif;
        }
    </style>
</head>

<style>
body {
  background-color: #CCFFFF;
  font-family: "Comic Sans MS", cursive, sans-serif, Arial, Helvetica, sans-serif;
  color: #9370DB;
  margin: 20px;
}

body {
  -webkit-text-size-adjust: 100%; /* For Safari and Chrome */
  -moz-text-size-adjust: 100%; /* For Firefox */
  -ms-text-size-adjust: 100%; /* For Internet Explorer and Edge */
  text-size-adjust: 100%;
}


h1 {
  color: #FF8C00;
  text-shadow: 2px 2px #808080;
  font-size: 2.5em;
}

h2 {
  color: #FF8C00;
  text-shadow: 2px 2px #808080;
  font-size: 2em;
}

h3 {
  color: #FF8C00;
  text-shadow: 2px 2px #808080;
  font-size: 1.5em;
}

p {
  line-height: 1.5;
  font-size: 1.2em;
}

.marquee {
  background-color: #FFFF00;
  color: #FF0000;
  padding: 5px;
  border: 2px dashed #000000;
}

.section {
  background-color: #FFFFFF;
  padding: 15px;
  border: 3px double #000000;
  margin-bottom: 20px;
}

.y2k-image {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 25%;
}

.y2k-quote {
  border: 3px dashed #008000; /* Green dashed border */
  background-color: #e0ffff; /* Light cyan background */
  padding: 25px;
  font-family: 'Comic Sans MS', 'Comic Sans', cursive; /* Classic Y2K font */
  font-size: 1.2em; /* Slightly larger font */
  line-height: 1.8;
  color: #00008b; /* Dark blue text */
  text-shadow: 1px 1px 2px #cccccc; /* Subtle text shadow for depth */
  border-radius: 10px; /*rounded corners*/
}

/*Optional, but adds to the chaotic feel*/
.y2k-quote:hover{
    background-color: #ffffe0; /*light yellow on hover*/
    border-color: #ffd700; /*gold border on hover*/
    color: #800080; /*purple text on hover*/
}

</style>

<marquee class="marquee" style="width: 100%; scrollamount: 10;">“What if your Fitbit knew exactly what to say on a particular day to motivate you to get off the couch and run a 5K?” - Persado, Schwab 2017</marquee>

<div class="section">
  <h1>Introduction</h1>

  <h3>New Tech and Mass Manipulation</h3>

  <p>
    Concerns regarding potential mass manipulation arise as new technologies use our data to predict and monetize on our behaviors. There are quite a few examples <strong>(links below)</strong>.
  </p>

  <img src="https://media4.giphy.com/media/E4cnIqDuNov1Pp10yC/giphy.gif?cid=ecf05e47w415f0p5r4v50444q807218z4155b41505r4v50444q807218z&ep=v1_gifs_search&rid=giphy.gif&ct=g" alt="Animated GIF" class="y2k-image">

  <p>
    <a href="https://www.geekwire.com/2016/uber-redesigns-app-predict-riders-headed-give-car/" target="_blank">"Uber redesigns app to predict where riders are headed and give them more to do in the car"</a>
  </P>

  <p>
    <a href="https://www.theguardian.com/technology/2014/oct/02/facebook-sorry-secret-psychological-experiment-users" target="_blank">The Facebook Experiment</a>
  </p>

  <p>
    <a href="https://noyb.eu/en/your-fitbit-useless-unless-you-consent-unlawful-data-sharing" target="_blank">FitBit Data Concerns</a>
  </p>

  <p>
    <a href="https://www.youtube.com/watch?v=iX8GxLP1FHo" target="_blank">Facebook and Cambridge Analytica (Trailer)</a>
  </p>

  <p>
    <strong>Key Concepts:</strong>
  </p>

  <p>
    <u>Hypernudging</u>: “drawing in Big Data to nudge individuals with personalized feedback to change their behavior” (Lanzing 2019)
  </p>

  <p>
    <u>Self-tracking</u>: “Fuelled by real-time data, algorithms create personalized online choice architectures that aim to nudge individual users to effectively change their behavior. ” (Lanzing 2019)
  </p>
  
  <p>
  *what is a <heavy>"<a href=“https://thedecisionlab.com/reference-guide/psychology/choice-architecture”>choice architecture</a>"</heavy> anyway? 
  </p>

  <h3>Research Paper Outline</h3>
  <p>
    <strong>Main goal:</strong> An ethical critique of self-tracking technologies and their data-collection-based algorithmic hypernudging.
  </p>

  <p>
    <strong>Theoretical Framework:</strong> decisional privacy and informational privacy as complementary dimensions
  </p>

  <p>
    <strong>Claim:</strong> self-tracking technologies and their hyper-nudging threatens individuals’ autonomy due to the fact that they violate both decisional and informational privacy.
  </p>

  <p>
    <strong>Four Steps:</strong>
  </p>

  <p>
    Nudging v.s. Hypernudging
    <a href="https://link.springer.com/article/10.1007/s13347-018-0316-4" target="_blank">
      (1.1 - 1.4)
    </a>
  </p>

  <p>
    Re-evaluation of decisional privacy
    <a href="https://link.springer.com/article/10.1007/s13347-018-0316-4" target="_blank">
      (1.5 -1.6)
    </a>
  </p>

  <p>
    Combination of informational privacy and decisional privacy
    <a href="https://link.springer.com/article/10.1007/s13347-018-0316-4" target="_blank">
      (1.7 - 1.9)
    </a>
  </p>

  <p>
    Three potential objections
    <a href="https://link.springer.com/article/10.1007/s13347-018-0316-4" target="_blank">
      (1.10)
    </a>
  </p>

</div>

<div class="section">
  <h2>Main Body</h2>

  <h3>Self-Tracking</h3>
  <p>
    <strong>Also known as:</strong>  “life-logging, quantified self, personal analytics, and personal informatics” (Lanzing 2019) 
  </p>

  <p>
  <strong>Definition:</strong> “the practice of quantifying behavior through extensive self-surveillance for the purpose of behavioral change”  (Lanzing 2019)
  </p>
  
  <p>
 <strong>How-to</strong>: wearable digital devices and/or smartphone apps + social media (external online platforms)

  </p>
 
  <p>
  <strong>Examples:</strong>
  </p>
  
  <p>
  <a href=“https://www.strava.com/features”>Strava</a>: self-tracking & social network for athletes
  </p>

 <p>
 Other Fitness apps: <a href=“https://en.wikipedia.org/wiki/Fitbit”>FitBit</a>, <a href=“https://runkeeper.com/cms/start-running/”>Runkeeper</a>
  </p>
  
 <div style="display: flex; align-items: center;">
  <img src="https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExaWNtZHRtNzdtMTdzcWt6NXo4NGEyaGJkNjlhNWpicmtoMHI2NDB1aSZlcD12MV9naWZzX3NlYXJjaCZjdD1n/5JOAtCLGugj3q/giphy.gif" alt="Animated GIF" style="max-height: 200px; margin-right: 10px;">
  <img src="https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExMWc0amhuY3I0bXRoOTFpeW9peGtzdzlpMTJ0cDFkZWhnZDIwYmEwMyZlcD12MV9naWZzX3NlYXJjaCZjdD1n/Q6ikViAiojf0bmU9PH/giphy.gif" alt="Animated GIF" style="max-height: 200px;">
</div>

   <p class="y2k-quote">
  “Big Data has enabled “personalized” choice architectures: choice architectures that are designed according to user data feedback. Personalized feedback in self-tracking is based on the analysis of large aggregates of (personal) information or “Big Data,” also referred to as personal analytics. The analysis aims to identify patterns and interesting correlations in the data. Based on the analysis, many devices, and apps make suggestions to their users about how they can change or improve their behavior, what choices to make.” (Lanzing 2019)
</p>
  
  <p>
   <strong>Main attraction: </strong> personalized feedback and thus self-improvement (and empowerment) 
  </p>
  
  <p>
  <strong>Main concern:</strong> Big Data-driven personalized choice architectures
  </p>
  
   <p>
   These are some interesting articles I found regarding self-tracking, feel free to take a look around!
  </p>
  
  <p>
  <a href="https://www.fabrique.com/blog/dark-side-self-tracking/">The Dark Side of Self-Tracking</a>
</p>
  
  <p>
  <a href="https://www.theguardian.com/lifeandstyle/2025/feb/22/the-bot-asked-me-four-times-a-day-how-i-was-feeling-is-tracking-everything-actually-good-for-us">‘The bot asked me four times a day how I was feeling’: is tracking everything actually good for us?</a>
  </p>
  
  <p>
  <a href="https://www.freedomlab.com/posts/everybody-is-a-self-tracker">Everybody is a self-tracker</a>
  </p>
  
  <h3>Nudging and Hypernudging</h3>

 <h4><strong><em>Features of Nudging</em></strong></h4>
 
 <p>
  1 critique:
  </p>
  
  <p>
  Potentially <u>manipulative</u>
  </p>
  
  <p class="y2k-quote">
 “Manipulation, as I understand it here, refers to the intentional but “hidden” steering of people’s choices by promoting and shaping decision-making processes that persons generally would not use for making rational decisions (Wilkinson 2013: 347; Goodin 1980: 17).” (Lanzing 2019)
</p>

  <p>
  2 <heavy>ideal</heavy> features:
  </p>

  <p style="margin-left: 20px;">
  I.Do not compromise individual freedom and autonomy. 
  </p>
  
  <p style="margin-left: 20px;">
  II.Do not reduce/eliminate options, simply re-arranging the individual’s choice architecture so it favors specific options.
  </p>
  
  <p>
  How do nudges work?
  </p>
  
  <p>
  Nudges influence and steer decision-making via <u>psychological mechanisms</u>.
  </p>
  
  <p>
  What are bad nudges?
  </p>
  
  <p style="margin-left: 20px;">
  I.Bad nudges rip the individual off their <heavy>control</heavy> over their behaviors. 
  </p>
  
  <p style="margin-left: 20px;">
  II.Bad nudges are <heavy>hardly noticeable</heavy> and their intentions are opaque, which could be potentially manipulative.
  </p>
  
  <p>
  What are good nudges? 
  </p>
  
  <p style="margin-left: 20px;">
  I.Good nudges are transparent and straightforward. 
  </p>
  
  <p style="margin-left: 20px;">
  II.Good nudges are easy to opt out of. 
  </p>
  
  <p style="margin-left: 20px;">
  III.Good nudges intend to improve the welfare of the nudgee.
  </p>
  
  <img src="https://media4.giphy.com/media/PkR8gPgc2mDlrMSgtu/giphy.gif?cid=ecf05e47n0211111666666666666666666666666666666666666666666666666666666r&ep=v1_gifs_search&rid=giphy" alt="Animated GIF" class="y2k-image">

  <h4><strong><em>Features of Hypernudging</em></strong></h4>
  <p>
  <strong>Also known as:</strong> “Big Data driven decision-guidance processes” “recommender systems.”
  </p>
  
  <p>
<strong>Definition:</strong> “the <u>algorithmic real-time personalization and reconfiguration</u> of choice architectures based on large aggregates of (personal) data.” (Lanzing 2019) 
  </p>
  
  <p class="y2k-quote">
 By constantly (re)-configuring and thereby personalizing the user’s informational choice context, typically through <strong>algorithmic analysis of data streams from multiple sources</strong> claiming to offer predictive insights concerning the habits, preferences, and interests of targeted individuals, these nudges channel users choices in directions <strong>preferred by the choice architect</strong> through processes that are subtle, unobtrusive, yet extraordinarily powerful (Yeung 2017: 119). (Lanzing 2019)
</p>

  <p>
<strong>Data source:</strong> 
  </p>
  
  <p>
Live data streams + Already stored data
  </p>
  
  <p>
Your personal data + All the data of other users 
  </p>

  <p>
  *Who is <u><a href=“https://algocracy.wordpress.com/2017/03/06/episode-20-karen-yeung-on-hypernudging-and-big-data/”>Yeung</a></u>?
  </p>
  
  <p>
  <strong>Examples:</strong> 
  </p>
  
  <p>
  <a href=“https://www.fitbudd.com/post/15-essential-features-for-a-custom-fitness-app”>Personalized Fitness App Motivations</a> 
  </p>
  
  <p>
  <a href=“https://www.builderfly.com/how-can-online-retailers-collect-and-use-consumer-data/#:~:text=Through%20this%20data%2C%20they%20monitor,what%20you%20purchased%2C%20what%20prompted”>Dynamic Pricing and Product Placement</a>
  </p>
  
  <p>
  <a href=“https://www.aeaweb.org/articles?id=10.1257/jep.28.2.51”>Tailored Political Messaging</a>
  </p>
  
  <p>
  <a href=“https://hubitat.com/blog/560491036715-what-smart-home-devices-can-monitor-energy-consumption”>Smart Home Energy Consumption Optimization</a>
  </p>
  
  <p>
  <a href=“https://www.bankrate.com/personal-finance/what-to-look-for-in-a-financial-wellness-app/”>Personalized Financial Advice</a>
  </p>
  
  <h4><i>Nudge v.s. Hypernudging</i></h4>
  
  | features | nudges | hypernudges |
|----------|----------|----------|
| dynamism (the real time, personalized feedback dynamic)| non-specific, aimed at the general public, "one size fits all"| one-to-many (millions!), real time, personalized, via surveillance and data collection|
| predictive capacity| no instant feedback and thus no immediate adjustment | real time algorithmic behavioral predictions and constant reconfiguration based on machine learning and instant feedback |
| hiddenness and hidden intentions (the final, overarching, and most important)| tucked away but still detectable, "visible" in the physical world| well-hidden, ubiquitous, unobtrusive, essentially for corporate profit, driven by high-tech|

  | A good Nudge Criteria | a nudge | a hypernudge |
|----------|----------|----------|
| transparency | low yet detectable | unobtrusive thus misleading & unjustified |
| easy to opt out of | could be | highly persuasive, well-hidden, system-default, opting out means quitting the service for good, and the option to opt out might not be clear (enough)|
| welfare for the nudgee| could benefit the nugee | essentially for corporate benefit, potentially more aligned with corporate interests |
  
  <h3>Decisional and Informational Privacy</h3>
  
  <h4><strong><em>Informational Privacy</em></strong></h4>
  
  <p>
   Definition: “the ability to control who has access to one’s personal information and to what extent (Westin 1967)" (Lanzing 2019)
  </p>
  
  <p>
  Related concept: reasonable expectations (dynamic and context dependent, constitute social norms)
  </p>
  
  <img src="https://media.giphy.com/media/arldiHgOAWyIw/giphy.gif?cid=ecf05e47my57pu9lp9cd6d5ji2dhg5soahm46wfqzey5qgzd&ep=v1_gifs_search&rid=giphy.gif&ct=g" alt="Animated GIF" class="y2k-image">
    
  <h4><strong><em>
  Decisional privacy as a complementary dimension:
  </em></strong></h4>
  
  <p>
  Definition: “the right against unwanted access such as unwanted interference in our decisions and actions (Allen 1988: 97; Roessler 2005: 9)” (Lanzing 2019)
  </p>
  
  <p>
  Descriptions: 
  </p>
  
  <p>
Narrow view: “nongovernmental decision-making ”, intimate choices
  </p>
  
  <p>
Broad view: fundamental life decisions, actions, modes of behavior, ways of life. 
  </p>
  
  <p>
<strong>In relation to autonomy:</strong> 
  </p>
  
  <p>
“regulates the access of others in the form of interpretation, objection, commenting, and other forms of intervention in the way you live your life.” (Lanzing 2019)
  </p>
  
  <p>
“provides the necessary breathing space to carry out one’s chosen life unhindered in different social contexts, which is important for leading a self-determined life and so, for autonomy (Roessler 2005: 80).” (Lanzing 2019)
  </p>
  
  <p>
“protects you from the interference of others, from the “chilling effect”: conforming your actions to perceived social norms out of fear for (social) sanctions. ” (Lanzing 2019)
  </p>
  
  <p>
<strong>In relation to hypernudging:</strong> 
  </p>
  
  <p>
Decisional privacy theories criticize how hypernudges use personal data to individuals decision-making process. 
  </p>

<p class="y2k-quote">
 Decisional privacy concerns should therefore not be reduced to or merely understood in terms of informational privacy concerns. Decisional privacy could be a promising complementary conceptual tool for criticizing hypernudging. (Lanzing 2019)
</p>

<p>
<strong>Key Takeaway:</strong>
</p>

<p>
The violation of one’s decisional privacy does not entail an immediate loss of personal autonomy. 
People should be regarded as autonomous agents who are free to make decisions and receive certain interferences depending on the social norms and contexts, however, commercial choice architectures and hypernudges intrude personal autonomy by bringing I commercially driven interferences in contexts where they are not welcome.
</p>

<p>
<strong>
interconnection:
</strong>
</p>

<p>
Informational and decisional privacy are both closely related to the protection of individual autonomy as two mutually reinforcing dimensions.
</p>

<p>
Violations of informational privacy naturally translate to the violations of one’s decisional privacy
</p>

<figure style="text-align: center;">
  <img src="/Users/olenonniboi/Desktop/Ethics of Privacy/Week_4/presentation lanzing/13347_2018_316_Fig1_HTML.jpg" alt="Example: the hypernudging feedback loop" width="250" style="display: block; margin: 50px auto;">
  <figcaption>Figure 1: The Hypernudging Feedback Loop</figcaption>
</figure>

<h4><strong>Hypernudge and informational privacy violations</strong></h4>

<p style="margin-left: 20px;">
I.People have no control over their data and data regarding their private decisions, nor the knowledge of how these data are used by commercial enterprises. 
</p>

<p style="margin-left: 20px;">
II.Big data-driven corporations and commercial third parties are blurring the boundaries between contexts and norms of sharing and accessing personal information. 
</p>

<p style="margin-left: 20px;">
III.Past behavioral data and data of an entire-population are used to hypernudge a specific individual, resulting in filter bubbles and collaborate filtering. 
</p>

<h4><strong>Hypernudge and decisional privacy violations</strong></h4>

<p style="margin-left: 20px;">
I.Hypernudges interfere people’s decision-making with hidden intentions and effects, people do not know why and how they are manipulated into making a choice that favors a third party.
</p>

<p style="margin-left: 20px;">
II.Not all options are visible and available to the nudgee, they are preselected by algorithms in favor of those in control of the technology.
</p>

<p style="margin-left: 20px;">
III.No accountability can be held. A nudgee does not know by whom their decisions are steered. 
</p>

<p style="margin-left: 20px;">
IV.Hypernudges affect many people in many domains at the same time.  
</p>

<h4><strong>Three Objections</strong></h4>

<p>
O1: Some people are willingly sharing there data in order to gain more independence via self-tracking technologies.
</p>

<p style="margin-left: 20px;">
Response: a technology that violates an individual’s informational and decisional privacy, and thus their autonomy, can not scaffold one’s autonomy.
</p>

<p>
O2: The fact that there are people using such technologies means that they consent to such operations and their effects. 
</p>

<p style="margin-left: 20px;">
Response: people consent to self-tracking technologies but their consents are no longer meaningful and informed. 
</p>

<p>
O3:Simply not using self-tracking technologies seems to be the most effective strategy.
</p>

<p style="margin-left: 20px;">
Response: not everyone can afford to fully opt out, let alone self-tracking technologies are becoming institutionalized. This simply avoids the issue rather than solving it. 
</p>

</div>

<div class="section">
  <h2>Conclusion and Further Yappin Session</h2>
  <p>
   post the discussion question right here
  </p>
  <img src="https://media1.giphy.com/media/3o6fJd6iEkL8Ys7tsY/giphy.gif?cid=ecf05e47p598p918r07j559555077797888878888888888888r&ep=v1_gifs_search&rid=giphy.gif&ct=g" alt="Animated GIF" class="y2k-image">
</div>